{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7637cec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset:\n",
      "Index(['vt_id', 'vt_app_type', 'vt_entry_term', 'satv_use', 'satm_use',\n",
      "       'satcomp_use', 'act_eng', 'act_math', 'act_read', 'act_sci', 'act_comp',\n",
      "       'nc1', 'nc2', 'nc3', 'ncav', 'EQ1', 'EQ2', 'EQ3', 'EQ4',\n",
      "       'EQ1_score-rator1', 'EQ1_score', 'EQ1_rator1', 'EQ1_score-rator2',\n",
      "       'EQ1_score-rator3', 'EQ1_score-rator4', 'EQ2_score-rator1',\n",
      "       'EQ2_score-rator2', 'EQ2_score-rator3', 'EQ2_score-rator4',\n",
      "       'EQ3_score-rator1', 'EQ3_score-rator2', 'EQ3_score-rator3',\n",
      "       'EQ3_score-rator4', 'EQ4_score-rator1', 'EQ4_score-rator2',\n",
      "       'EQ4_score-rator3', 'EQ4_score-rator4', 'hs_gpa', 'college_gpa',\n",
      "       'vt_major', 'vt_coll', 'vt_gpa_1yr', 'vt_grad_gpa', 'vt_adm_dec',\n",
      "       'vt_app_response', 'enr_after_first_yr', 'gender', 'age', 'ethnic/race',\n",
      "       'country_citz', 'residency', 'state'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'AI Psych Project_2019_data.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Output the columns\n",
    "columns = data.columns\n",
    "print(\"Columns in the dataset:\")\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb111697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows based on the 'vt_adm_dec' column\n",
    "values_to_keep = ['Admit (Offers Admission)', 'Waitlist', 'Deny (Rejects)']\n",
    "data = data[data['vt_adm_dec'].isin(values_to_keep)]\n",
    "data = data.reset_index(drop=True)\n",
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30ec79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer('Alibaba-NLP/gte-large-en-v1.5', trust_remote_code=True)\n",
    "\n",
    "# Compute embeddings for each column and add to the DataFrame\n",
    "for col in ['EQ1', 'EQ2', 'EQ3', 'EQ4']:\n",
    "    embeddings = model.encode(data[col])\n",
    "    data[f'{col}_embeddings'] = embeddings.tolist()\n",
    "\n",
    "# The DataFrame now contains the embeddings for EQ1, EQ2, EQ3, and EQ4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f29d2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is already created and named `data`\n",
    "data.to_pickle(\"data2.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llama)",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
